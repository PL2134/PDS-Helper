{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ad9b4b85-9d17-468c-b244-73a1c5191e3e",
   "metadata": {
    "id": "ad9b4b85-9d17-468c-b244-73a1c5191e3e"
   },
   "source": [
    "# RAG application built on IAG PDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "78u85jvroZzI",
   "metadata": {
    "id": "78u85jvroZzI"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory: /Users/pauline/Desktop/github_repos/rag-ai-chatbot\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Define the path to your local project folder\n",
    "persistent_folder = \"/Users/pauline/Desktop/github_repos/rag-ai-chatbot/\"\n",
    "\n",
    "# Create the folder if it doesn't exist\n",
    "os.makedirs(persistent_folder, exist_ok=True)\n",
    "\n",
    "# Change directory to the project folder\n",
    "os.chdir(persistent_folder)\n",
    "\n",
    "print(f\"Current working directory: {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7d49c22a-1ad0-4395-b93b-aa95660aa026",
   "metadata": {
    "id": "7d49c22a-1ad0-4395-b93b-aa95660aa026"
   },
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "loader = PyPDFLoader(\"iag_pds.pdf\")\n",
    "data = loader.load()  # entire PDF is loaded as a single Document\n",
    "#data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a374eb7c-e262-42bb-8f3f-308ba7dcdbe4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a374eb7c-e262-42bb-8f3f-308ba7dcdbe4",
    "outputId": "d76bc135-9acb-4815-ea07-96b952d7da1f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "74"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "29633e3b-ff24-4ace-a09b-c03b6e28c5cc",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "29633e3b-ff24-4ace-a09b-c03b6e28c5cc",
    "outputId": "f29fa6a9-5d4b-4495-ea45-42e1cb50925f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of documents:  270\n"
     ]
    }
   ],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "# split data\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000)\n",
    "docs = text_splitter.split_documents(data)\n",
    "\n",
    "\n",
    "print(\"Total number of documents: \",len(docs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "100b7d1a-1209-49d4-99ed-c51bc233a938",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "100b7d1a-1209-49d4-99ed-c51bc233a938",
    "outputId": "f6fe61ce-5f2a-4593-8c5d-bb37e0691d8e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'producer': 'Adobe PDF Library 15.0', 'creator': 'Adobe InDesign CC 2015 (Macintosh)', 'creationdate': '2016-05-10T14:59:33+12:00', 'moddate': '2017-02-24T17:04:34+11:00', 'trapped': '/False', 'source': 'iag_pds.pdf', 'total_pages': 74, 'page': 3, 'page_label': '3'}, page_content='will not receive any compensation, and you have no right to take action against IAG if \\nany of your Notes are Written-Off \\nReceipt of Ordinary Shares on \\nConversion\\nYou will receive approximately NZ$1.01 worth of Ordinary Shares for each of your \\nNotes that is Converted, unless a cap referred to as the “Maximum Conversion \\nNumber” applies – see Section 6.7 of this PDS (Conversion formulae). It is likely the \\nMaximum Conversion Number will apply following a Non-Viability Trigger Event, \\nin which case you may receive significantly less than NZ$1.01 worth of Ordinary \\nShares for each of your Notes that is Converted')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1073ab7f-2632-4367-8dec-c19449d6ce71",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1073ab7f-2632-4367-8dec-c19449d6ce71",
    "outputId": "e7d773a8-eabf-4e32-acc1-3ad99aa4b5e0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.05168594419956207,\n",
       " -0.030764883384108543,\n",
       " -0.03062233328819275,\n",
       " -0.02802734263241291,\n",
       " 0.01813093200325966]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_chroma import Chroma\n",
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "#Get an API key:\n",
    "# Head to https://ai.google.dev/gemini-api/docs/api-key to generate a Google AI API key. Paste in .env file\n",
    "\n",
    "# Embedding models: https://python.langchain.com/v0.1/docs/integrations/text_embedding/\n",
    "\n",
    "embeddings = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\")\n",
    "vector = embeddings.embed_query(\"hello, world!\")\n",
    "vector[:5]\n",
    "#vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "688b6e6a-d8ab-41fb-a665-b72c9c9b4026",
   "metadata": {
    "id": "688b6e6a-d8ab-41fb-a665-b72c9c9b4026"
   },
   "outputs": [],
   "source": [
    "vectorstore = Chroma.from_documents(documents=docs, embedding=GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2c674c5c-1b57-42e9-a99d-9e882c75da2d",
   "metadata": {
    "id": "2c674c5c-1b57-42e9-a99d-9e882c75da2d"
   },
   "outputs": [],
   "source": [
    "retriever = vectorstore.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 10})\n",
    "\n",
    "retrieved_docs = retriever.invoke(\"What is a Non-Viability Trigger Event?\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "04c5c6bb-fd0e-45ec-b315-e3f7656e0329",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "04c5c6bb-fd0e-45ec-b315-e3f7656e0329",
    "outputId": "0e9f35cf-1d29-4212-f196-8a3ac74267c3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(retrieved_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8a1c8321-1efd-4a11-9744-0d1a7c6f4e0a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8a1c8321-1efd-4a11-9744-0d1a7c6f4e0a",
    "outputId": "35a78d91-9d5b-4976-a329-2a2c8bb0c64d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "• IAG would be required on the next payment due on the Notes to pay an additional amount in \n",
      "respect of a withholding or deduction on account of taxes on a payment on the Notes;\n",
      "• IAG or the consolidated tax group of which it is a member would be exposed to more than a de \n",
      "minimis amount of other taxes, assessments or other governmental charges in connection with \n",
      "the Notes; or\n",
      "• IAG determines that any interest payable on the Notes is not or may not be allowed as a \n",
      "deduction for the purposes of Australian income tax,\n",
      "provided that on the Issue Date, IAG did not expect that matters giving rise to the Tax Event  \n",
      "would occur\n",
      "Tier 1 Capital Tier 1 capital (as defined by APRA from time to time)\n",
      "Tier 2 Capital Tier 2 capital (as defined by APRA from time to time)\n",
      "Trigger Event Date the date on which APRA notifies IAG that a Non-Viability Trigger Event has occurred\n",
      "Trust Deed the trust deed dated 4 May 2016 between IAG and the Supervisor, as amended from time to time.\n"
     ]
    }
   ],
   "source": [
    "print(retrieved_docs[5].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7f991a1f-6ce9-4463-9941-b35014df94f6",
   "metadata": {
    "id": "7f991a1f-6ce9-4463-9941-b35014df94f6"
   },
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-1.5-pro\",temperature=0.3, max_tokens=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6ee17439-7bc3-4931-9f57-4ec7e82ce902",
   "metadata": {
    "id": "6ee17439-7bc3-4931-9f57-4ec7e82ce902"
   },
   "outputs": [],
   "source": [
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "system_prompt = (\n",
    "    \"You are an assistant for question-answering tasks. \"\n",
    "    \"Use the following pieces of retrieved context to answer \"\n",
    "    \"the question. If you don't know the answer, say that you \"\n",
    "    \"don't know. Use three sentences maximum and keep the \"\n",
    "    \"answer concise.\"\n",
    "    \"\\n\\n\"\n",
    "    \"{context}\"\n",
    ")\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system_prompt),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "266e86e0-746b-4943-9470-fd842633ed85",
   "metadata": {
    "id": "266e86e0-746b-4943-9470-fd842633ed85"
   },
   "outputs": [],
   "source": [
    "question_answer_chain = create_stuff_documents_chain(llm, prompt)\n",
    "rag_chain = create_retrieval_chain(retriever, question_answer_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9db9500d-4c51-4a10-9b21-f1ef9c8f985e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9db9500d-4c51-4a10-9b21-f1ef9c8f985e",
    "outputId": "09184ea7-d0d1-4f5c-e598-9479a56c3648"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A Non-Viability Trigger Event occurs if APRA determines that IAG would become non-viable without converting or writing off capital instruments (like Notes) or receiving a public sector capital injection.  This event is triggered at APRA's discretion and may include, but isn't limited to, serious impairment of IAG’s financial position and solvency.  Several factors, including macroeconomic conditions and the financial health of IAG's subsidiaries, can impact IAG's viability.\n"
     ]
    }
   ],
   "source": [
    "response = rag_chain.invoke({\"input\": \"What is a Non-Viability Trigger Event?\"})\n",
    "print(response[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "P2GbpAXsBHfH",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "P2GbpAXsBHfH",
    "outputId": "35a2f539-a2b5-4c72-8bcd-5e4434133888"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[32mRunning server on: http://localhost:32123\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import mesop as me\n",
    "import mesop.labs as mel\n",
    "\n",
    "me.colab_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "AtXPVRu7CaX1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 422
    },
    "id": "AtXPVRu7CaX1",
    "outputId": "a8c7f72b-c361-47da-cb7c-6297465c9cc7"
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "(async (port, path, width, height, cache, element) => {\n",
       "    if (!google.colab.kernel.accessAllowed && !cache) {\n",
       "      return;\n",
       "    }\n",
       "    element.appendChild(document.createTextNode(''));\n",
       "    const url = await google.colab.kernel.proxyPort(port, {cache});\n",
       "    const iframe = document.createElement('iframe');\n",
       "    iframe.src = new URL(path, url).toString();\n",
       "    iframe.height = height;\n",
       "    iframe.width = width;\n",
       "    iframe.style.border = 0;\n",
       "    iframe.allow = [\n",
       "        'accelerometer',\n",
       "        'autoplay',\n",
       "        'camera',\n",
       "        'clipboard-read',\n",
       "        'clipboard-write',\n",
       "        'gyroscope',\n",
       "        'magnetometer',\n",
       "        'microphone',\n",
       "        'serial',\n",
       "        'usb',\n",
       "        'xr-spatial-tracking',\n",
       "    ].join('; ');\n",
       "    element.appendChild(iframe);\n",
       "  })(32123, \"/chat\", \"100%\", \"400\", false, window.element)"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define the chat function and connect to RAG model\n",
    "@me.page(path=\"/chat\")\n",
    "def chat():\n",
    "    mel.chat(transform)\n",
    "\n",
    "# Modify transform to use RAG to generate responses\n",
    "def transform(prompt: str, history: list[mel.ChatMessage]) -> str:\n",
    "    # Assuming rag_chain is your RAG pipeline\n",
    "    response = rag_chain.invoke({\"input\": prompt})\n",
    "    return response[\"answer\"]  # Return the RAG model's answer\n",
    "\n",
    "# Display the chat window in Colab\n",
    "me.colab_show(path=\"/chat\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2shfU-iOEp4I",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 280
    },
    "id": "2shfU-iOEp4I",
    "outputId": "f3eb9f80-ee07-4c13-8a89-3dc9a051ccdd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[32mRunning server on: http://localhost:32123\u001b[0m\n",
      " * Serving Flask app 'mesop.server.server'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Address already in use\n",
      "Port 32123 is in use by another program. Either identify and stop that program, or start the server with a different port.\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'mesop' has no attribute 'run'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-a37ad573edf0>\u001b[0m in \u001b[0;36m<cell line: 19>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;31m# Start the Mesop server on port 8080\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0mme\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mport\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8080\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: module 'mesop' has no attribute 'run'"
     ]
    }
   ],
   "source": [
    "import mesop as me\n",
    "import mesop.labs as mel\n",
    "\n",
    "# Initialize Mesop as usual\n",
    "me.colab_run()\n",
    "\n",
    "# Define the chat UI page and connect it to the RAG model\n",
    "@me.page(path=\"/chat\")\n",
    "def chat():\n",
    "    mel.chat(transform)\n",
    "\n",
    "# Modify transform to use the RAG model to generate responses\n",
    "def transform(prompt: str, history: list[mel.ChatMessage]) -> str:\n",
    "    # Assuming rag_chain is your RAG pipeline\n",
    "    response = rag_chain.invoke({\"input\": prompt})\n",
    "    return response[\"answer\"]  # Return the RAG model's answer\n",
    "\n",
    "# Start the Mesop server on port 8080\n",
    "me.run(port=8080)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a766ac4-fd27-4bd8-b942-600218b868de",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python (rag)",
   "language": "python",
   "name": "rag"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
